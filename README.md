# dnnl_perf
A simple inference bench from Intel DNNL -https://github.com/intel/mkl-dnn. You can compile it out of tree.
The benchmark implements AlexNet topology using DNNL
> Deep Neural Network Library (DNNL) is an open-source performance library for deep learning applications.
> The library includes basic building blocks for neural networks optimized for Intel Architecture Processors and Intel Processor Graphics.

## build
```
$ make
```

## test
```$ ./cnn_inference_f32``` 
